# NeurIPS 2025 Ariel Data Challenge â€“ Solution Overview

This repository contains a solution for the **NeurIPS 2025 Ariel Data Challenge**, titled *â€œAdvancing Exoplanetary Signal Extraction for the Ariel Space Telescope.â€*  
In this competition, participants extract extremely faint exoplanetary signals (atmospheric spectra) from noisy simulated telescope data and provide uncertainty estimates.  
Official challenge links:
- https://www.kaggle.com/competitions/ariel-data-challenge-2025


---

## ğŸ§  Methodology and Core Techniques

This solution uses a hybrid pipeline of signal processing and deep learning to clean the data, detect transits, predict exoplanet spectra, and estimate uncertainties.

### ğŸ”¹ Savitzkyâ€“Golay Filtering
- Smooths the time-series using local polynomial fits.
- Preserves transit shapes while reducing high-frequency noise.

### ğŸ”¹ Moving Average Smoothing
- Suppresses spikes or instrument noise by averaging neighbors.
- Used together with SG-filter for robust signal cleaning.

### ğŸ”¹ Phase Detection & Polynomial Fitting
- Detects transit start/end points using gradient changes.
- Fits polynomial to out-of-transit baseline.
- Optimizes transit depth scale (*s*) using Nelderâ€“Mead.

### ğŸ”¹ ResNet-Based Signal Prediction
- ResNet model predicts:
  - Coarse transit depth (first channel)
  - Full transmission spectrum (282 channels)
- Inputs include: polynomial signal, stellar metadata (Rs, i)
- Ensemble average improves robustness.

### ğŸ”¹ Linear Regression for Sigma Estimation
- Uses std-dev of predictions to estimate uncertainty (Ïƒ).
- Model: `linear_model_use2_to_sigma.joblib`
- Same Ïƒ applied to all channels for each planet.

---

## ğŸ“ Repository Contents

| File | Description |
|------|-------------|
| `trainanpy.ipynb` | Model training on cleaned training data |
| `resnet-for-airs-finetuned.ipynb` | Final pipeline for test-time prediction |
| `data.py` | Polynomial-based transit model and preprocessing |
| `linear_model_use2_to_sigma.joblib` | Linear model to predict sigma from prediction std-dev |

---

## âš™ï¸ Installation and Dependencies

```bash
pip install torch numpy pandas scipy scikit-learn astropy tqdm pqdm matplotlib
```

Python 3.9+ recommended. GPU is highly recommended for model training and inference.

---

## ğŸš€ How to Use

### 1. Download Dataset
From the [Kaggle challenge page](https://www.kaggle.com/competitions/ariel-data-challenge-2025) and place in a folder:
```python
ROOT_PATH = "/your/local/data/path"
```

### 2. Preprocessing & Feature Extraction
Run notebooks directly â€” preprocessing (SG filter, moving average, polynomial model) is built-in.

### 3. Train Models (optional)
```python
# Inside trainanpy.ipynb
# Trains ResNet models + saves .pth weights
```

### 4. Run Inference
```python
# Inside resnet-for-airs-finetuned.ipynb
# Loads pretrained weights + predicts spectrum and sigma
```

Ensure:
- `linear_model_use2_to_sigma.joblib` is in root dir
- model weights are correctly referenced or trained

---

## ğŸ“¤ Output Format

Final output: `submission.csv`

| planet_id | wl_1 | ... | wl_283 | sigma_1 | ... | sigma_283 |
|-----------|------|-----|--------|---------|-----|-----------|
| 1103775 | 0.016 | ... | 0.0159 | 0.000275 | ... | 0.000275 |

- `wl_*`: transit depth (atmospheric spectrum)
- `sigma_*`: corresponding uncertainty (Ïƒ)

---

## ğŸ” Notes

- Code was developed for Kaggle kernel, paths may need adjusting.
- Memory-heavy: inference with CPU may be slow; GPU strongly recommended.
- Predictions depend on ResNet weights â€” for reproducibility, ensure correct versions are used.

---

## ğŸ“Œ Conclusion

This repo provides a complete solution to the NeurIPS 2025 Ariel Data Challenge using classical signal processing and modern deep learning. Itâ€™s extensible to future exoplanet missions like ESA's Ariel, and may support further research in denoising astrophysical time-series.
